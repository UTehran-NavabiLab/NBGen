---------------------------------------- TODO list ----------------------------------------
    20Feb;
        at this point all the functions are independent
            make a class out of functions 
            this way we can share attributes like dir, reduce the overhead of passing so many arguments
    19Jan;
        making some changes to vesal technology reader
        project: [technology_reader]
            create a dictionary for dff 
                self.dict_of_dff.update({cell.args[0]: {
                    "output" : self.find_dff_Q_signal(cell),
                    "next_state": self.find_dff_D_signal(cell),
                    "clocked_on": self.find_dff_clk(cell),
                    "preset": self.find_set_signal(cell),
                    "clear": self.find_rst_signal(cell)
                }})
        [utilities_functions.py]
            function find_clk_rst_netNumber takes technology_parameter 
                it contains list of all DFFs
                search all cell for dff types 
                list signal numbers that connects to its ports
            function find_clk_rst_name takes list of numbers
                check in design input ports for that signal number 
                if find returns the corresponding names
        [script.py]
            change all netlist->js2** to take config.json (instead of tech.json)
            in future completely remove the dependencies for tech.json and get rid of it
        [config.json]
            add value to point to library 
                "library_directory": "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/utdate/lib/NangateOpenCellLibrary_typical.lib",
            take 45nm as default library 
            place it into library of package to be accessed everywhere
        [json2**.py]
            substitute tech_js with config_js
            in future remove all dependencies to tech_json
        
    18Jan;
        adding technology_parser class written by Vesal:
            merge vesal codes to mine and create a bigger technology class
                /Users/ebinouri/Documents/UNi/OpenSourceTools/power_analysis_framework/testsuites/liberty_parser_test/liberty2json.py    

- support for inout bus
- search source file for todo's
- make it independent of tech file, reading the library directly and extract pin names
    don't pass tech file as input to classes
- if design is not flattened, there several module in hierarchical order 
    right now only top module is being read from json file and turn into systemc netlist 
    add option to read all internal modules (in case that the design is not flatten) and create a separate sc_module for each

- add option to use user-defined yosys script choosing from file 
    right now if there is no input file in first page, synthesis is not possible 
    change it so that providing yosys script, synthesis would be possible based on script

- read dff name automatically from .lib and fill tech.js file

- replace manual dff list checking with a function

 create a list of defective dff
- to repair:
    get the list of defective dff
    {   for every dff in list{
            find input port 
            add mux, meaning:
                write corresponding string 
        }
        return string
    }

    open module.v in append mode 
        append string
    call yosys process 

------------------
script->netlist: json2sc_testbench_pwr()
    power testbench & power netlist is hardcoded 

json2sc_testbench_pwr -> signaling_process -> right now only one transition is covered
    - using utilities.h -> input_signaling: make input for all possible transition

add option to be yosys compatible 
    (so far it's hard coded only for systemc)
    do it for verilog and vhdl and make it optional


* change indexing of gates in order of types
    to be compatible with qflow 
* check out what's with new prefix

create a "configuration paga" to configure json file 
add lookup list to choose cell library
add "iverilog"/"ghdl" simulator for verilog/vhdl simulation
add option to use existing "fault list" and "test vector"
seperate ATPG and FLTG: make report section for each one
for fault simulation process:  
    add a loading icon to show simulation is in process
    make clock cycle variable by user
    * on [json2sc_testbench->size_Of_Ports] we excluded reset and clock for sizePI
        consider the possibility of designs having no reset
    
report error for each stage properly

why the number of faults generated by Atalanta is different from yours

modules with a name equal to one of the signals would cause error on systemc (see counter example)
te'daade hirarchy vaase fault_list generation mitoone tavasote user moshakhas beshe?

---------------------------------------- Automating flow for power analysis ----------------------------------------
config which library to use
Netlist:
    - #include "Complex_NAgate_45.h"
    - #include "sc_signal_pw.h"
    - use sc_signal_pw with proper naming
testbench:
    - include proper lib
    - use sc_signal_pw with proper naming
    - add sc_event
    - add power module
        power_analysis *p_module;
    - add signal array:
        std::array<sc_signal_pw<sc_logic>*, 5> signal_arr;
    


---------------------------------------- Done ----------------------------------------
    21Dec;  
        json2systemc -> gate_signal_dict
            port association is by name (not by order)
            {gate: [{port_name: signal}, {port_name: signal}]}
add bunch of checkbox
finish fault sim part
sayac scan simulation on systemc
automating fault simulation process:
    + - choose the right "fault-injector" module (based on comb/seq) and copy that in test folder
        check if there is any DFF
    + - automatic testbench Gen (for combinational and seq):
        for seq circuit it's important to know what is the name of clock and reset
        we should order input_ports in way that special pin are always in same order
    + - put them all in one folder and call "make" file
    + - remove "END" line from test vector
    + - copy testVector/fault_list to faultSim folder [and rename them]
    + - input testbench name and faulty_instance 
    + - fix {last_dff_Q_port}
** complete [->so_assignment_method] && dff changes duo to scan insertion
counter scan simulation on systemc
verify systemc vs vhdl
fix atalanta float problem
lenght of test data is not fix: fault injector module : fixed using templated class

sayac Netlist


- fix "utilies_functios" name
---------------------------------------- Notes ----------------------------------------
on testbench for counter :
    *[we changed the order of inputs to be compatible with given test vectors]
        in the end changed it back to its normal order

[utilies_functios->rm_float_net,find_clk_rst_netNumber, find_clk_rst_name]: are specific to "abc_my_cells.lib"

synthesizing SAYAC Netlist:
    to synthesize netlist of SAYAC: we had to change "dff" description to fit ghdl compilation constraints
    to synthesize SAYAC along with mem and inst_rom: we comment out codes and assign input to output
        produce dff with asynch reset 
            > added "async2sync" to script to convert asynch to normal dff
    we get an error of 
        error: use of synopsys package "std_logic_textio" needs the -fsynopsys option

    - then we observe a bigger problem:
        while trying to synthesis one of our dff, we realized that it produce two sets of DFF {$_DFF_PN0_, _DFFSR_PPP_} just for one of them
            probably because our dff is a complex dff with asynch set and reset
            only after using "async2sync" command we get two set of fully synch DFF {_DFF_P_, _SDFF_PN0_}
    
    - we tried to solve this issue by using "extract" command again
    
GUI:
    - for callback function don't use () else they executes at start of program


----------------- Python relative import and package problem: 

first there was a problem with relative importing of one package from a sibling package
    https://stackoverflow.com/questions/6323860/sibling-package-imports

to solve I decided to make a local package using setuptool
then I realized that there is conflict between different versions of python that i have
    I) I have four version of python installed (each have their own pip)
        - native python-2 was pre-installed
        - python3.9 installed using brew
            python@3.9: stable 3.9.13 (bottled)
            /usr/local/Cellar/python@3.9/3.9.13_1 (3,093 files, 55.9MB)
            They will install into the site-package directory
            /usr/local/lib/python3.9/site-packages
        - python3.10 installed using brew (this is a most updated version)
            python@3.10: stable 3.10.5 (bottled) [keg-only]
            /usr/local/Cellar/python@3.10/3.10.5 (3,150 files, 57.2MB)
            Python has been installed as
            /usr/local/opt/python@3.10/bin/python3
            They will install into the site-package directory
            /usr/local/lib/python3.10/site-packages
        - python3.10 installed manually (probably to support tk)
            /Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10
            /Library/Frameworks/Python.framework/Versions/3.10/bin/pip3
    II) some version of python does not support tk
    III) there is a miss matching of python/pip version that on path and get called normally (not referenced explicitly)
        when I execute 
            > python3
            what I get is: /Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 (which supports tk)
        when I execute
            > pip3
            It calls: /usr/local/lib/python3.10/site-packages/pip (which the version installed by brew)
so if I want to install local package using pip3 I should address which one explicitly

----------------- Creating local package using setuptool 
    https://stackoverflow.com/questions/6323860/sibling-package-imports

----------------- Creating online Pypi package 
https://www.youtube.com/watch?v=v4bkJef4W94
https://packaging.python.org/en/latest/tutorials/packaging-projects/

Uploading the distribution archives
To securely upload your project, you’ll need a PyPI API token. 
Create one at https://test.pypi.org/manage/account/#api-tokens, setting the “Scope” to “Entire account”. 

[testpypi]
    username = __token__
    password: pypi-AgENdGVzdC5weXBpLm9yZwIkNWM0MWE2NjYtNjFiYy00YzdkLTkxZTAtY2QzYjY5YmVkODEzAAIleyJwZXJtaXNzaW9ucyI6ICJ1c2VyIiwgInZlcnNpb24iOiAxfQAABiBalV4e0AW3J68SKZpne_6k-gz9MfwzNKVgIuxLhAmj-A

to add assets(images) to package use 
    > include_package_data = True
    inside setup.cfg

----------------- process of updating package on Pypi 
*[read manual above to refresh]
** for backend tool, always use latest version of setuptool in file [pyproject.toml]

create dist folder:
    > python3 -m build
upload using twine:
    > python3 -m twine upload --repository testpypi dist/*
enter user and password:
    username = __token__
    password: pypi-AgENdGVzdC5weXBpLm9yZwIkNWM0MWE2NjYtNjFiYy00YzdkLTkxZTAtY2QzYjY5YmVkODEzAAIleyJwZXJtaXNzaW9ucyI6ICJ1c2VyIiwgInZlcnNpb24iOiAxfQAABiBalV4e0AW3J68SKZpne_6k-gz9MfwzNKVgIuxLhAmj-A

to install:
    > /Library/Frameworks/Python.framework/Versions/3.10/bin/pip3 install -i https://test.pypi.org/simple/ utdate==0.0.10
to uninstall:
    > /Library/Frameworks/Python.framework/Versions/3.10/bin/pip3 uninstall utdate
to list all packages in site-package:
    > /Library/Frameworks/Python.framework/Versions/3.10/bin/pip3 list

to Run module:
    > python3 -m udate
    doing that, (__main__.py) gets called and starts program

----------------- compatiblility with qflow
yosys:
    for verilog:
        name the wire consecutively starting from _0_
        then continues indexing gates
    for blif
        retains the same wiring naming
        but gates has no names (since it defined them as .gate, later on qflow changes them to be .subckt)
    for json:
        gates name is the key in cells dictionary
qflow:
    for blif:
        takes yosys output
    for verilog:
        name retains wire naming 
        but for gates considers the type:
            INV_X1 INV_X1_1  ( .A(i0), .ZN(_8_) );
            NAND2_X1 NAND2_X1_1  ( .A1(i1), .A2(ci), .ZN(_0_) );
            INV_X1 INV_X1_2  ( .A(i1), .ZN(_1_) );
            INV_X1 INV_X1_3  ( .A(ci), .ZN(_2_) );
    

-------------------- Adding new feature to GUI --------------------
    we use figma platform to design 
        [https://www.figma.com/]
    we then extract design to tkinter format using tkinter-designer
        [https://github.com/ParthJadhav/Tkinter-Designer]
    tkinter-designer has some constraints on naming of elements
        [https://github.com/ParthJadhav/Tkinter-Designer/blob/master/docs/instructions.md]
    when designing is done, open tkdesigner gui 
    copy url & token (get token from setting in figma)

-------------------- How GUI works --------------------
    by calling the package 
        > python3 -m utdate 
        the __main__.h executes
    it creates the root window and immediately disable it 
    then it calls the mainWindow 
    mainWindow is a toplevel entity of tkinter
    inside mainWindow:
        we create a main canvas that is plate for all elements 
        we place sidebar on the left
        create a dictionary of windows
            creating this object in main window makes them child of this class
            we would normally pass pointer to main window to every page 
                this way we can access properties of other pages anywhere, when needed
            call each page constructor while creating an object on dictionary
            also, having this object in main window
        call create_all_pages():
            place all window in their position
            raise the file page to stand out and hide other pages 
            put sidebar_indicator (red ribbon beside button) on respective button (file)
            raise the sidebar_indicator to front
        disable resizing feature 
        start mainloop()
    
    InputFile page:
        inside constructor:
            store pointer to parent (mainWindow) 
            store working directory
            initial some variables
                file_directory
                file_entry_box
                delete_file_btn
            create canvas
            place elements on canvas 
            for buttons, detemine callback functions 
            write callback functions





-------------------- Making process tech-library independent --------------------
finding dependencies in files:
    utility_functions.py:
        lut2gate
        remove_DFFport
        find_clk_rst_netNumber
        rm_float_net
    
    json2hdl.py:
        is_sequential_check

    json2systemc.py:
        number_of_DFF
        get_each_cell
        includes:
            include file is specific to our component library
    
    json2systemc_flt.py:
        get_each_cell
        cells_declaration
    
    fault_collapsing.py:
        all

make a json file for technology
check if "tech.json" exist in working directory
if not use default json file in utdate/lib/tech.json
script.py:
    ask for library file in yosys_script
    check each function for tech dependencies
        modify function signature along with all its instances
    

    